{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_utf8(item):\n",
    "    if isinstance(item, str):  # If item is a string\n",
    "        try:\n",
    "            return item.encode('latin1').decode('utf-8')\n",
    "        except:\n",
    "            return item  # Return original if decoding fails\n",
    "    elif isinstance(item, list):  # If item is a list\n",
    "        return [decode_utf8(x) for x in item]\n",
    "    elif isinstance(item, dict):  # If item is a dictionary\n",
    "        return {key: decode_utf8(value) for key, value in item.items()}\n",
    "    else:  # If item is neither string, list nor dict (could be int, bool, etc.)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_n_decode(data_in, file_name):\n",
    "    splited_data = data_in.replace(\"b'{\", 'b\"{').split('b\"')\n",
    "    arr_data = [spld.replace(\"\\\\'\", \"'\") for spld in splited_data]\n",
    "\n",
    "    json_data_arr = []\n",
    "    \n",
    "    for i in range(len(arr_data)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        elif \"TikTokApi.video(\" in arr_data[i]:\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                # clean & decode UTF-8\n",
    "                content = arr_data[i].replace(\"'\", '\"')[:-2]\n",
    "                content = re.sub(r'([A-Za-z])\"(?=[A-Za-z])', r\"\\1'\", content) # reg replace from Don\"t to Don't\n",
    "\n",
    "                # # analyze error\n",
    "                # pattern1 = r'\"title\":\\s*\"(.*?)\"'\n",
    "                # pattern2 = r'\"desc\":\\s*\"(.*?)\"'\n",
    "                # updated_string = re.sub(pattern1, '\"title\": \"ignore string error\"', content)\n",
    "                # updated_string = re.sub(pattern2, '\"desc\": \"ignore string error\"', updated_string).replace(\"True\", \"true\").replace(\"False\", \"false\")\n",
    "\n",
    "                str_data = ast.literal_eval(content)\n",
    "                decoded_data = str(decode_utf8(str_data)).replace(\"'\", '\"').replace(\"True\", \"true\").replace(\"False\", \"false\").replace(\"\\\\\\\\n\", \" \")\n",
    "                updated_string = re.sub(r'([A-Za-z])\"(?=[A-Za-z])', r\"\\1'\", decoded_data) # reg replace from Don\"t to Don't\n",
    "                # print(updated_string) # print and paste this on the .json file to see if there's an error\n",
    "\n",
    "                # turn string into object\n",
    "                json_data = json.loads(updated_string)\n",
    "                id = json_data[\"id\"]\n",
    "\n",
    "                # print(id, json_data)\n",
    "\n",
    "                # # export to check json data\n",
    "                # file_path = r\"./exported-accountpage-json-error-check/\" + file_name[:-4] + \"-\" + id + \".json\"\n",
    "                # with open(file_path, \"w\", encoding='utf-8') as file:\n",
    "                #     json.dump(json_data, file, indent=4, ensure_ascii=False)\n",
    "                \n",
    "                \n",
    "                json_data_arr.append(json_data)\n",
    "                # break # uncomment this for one time loop\n",
    "            except:\n",
    "                print(file_name + ' error inside function')\n",
    "                break\n",
    "    return json_data_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nested_keys(my_dict):\n",
    "\n",
    "    keys_to_extract = [\n",
    "        [\"author\", \"uniqueId\"],\n",
    "        [\"author\", \"signature\"],\n",
    "        [\"author\", \"verified\"],\n",
    "        \"desc\",\n",
    "        \"verified\",\n",
    "        \"createTime\",\n",
    "        \"digged\",\n",
    "        \"duetDisplay\",\n",
    "        \"duetEnabled\",\n",
    "        \"forFriend\",\n",
    "        \"id\",\n",
    "        \"itemCommentStatus\",\n",
    "        [\"music\", \"authorName\"],\n",
    "        [\"music\", \"coverLarge\"],\n",
    "        [\"music\", \"duration\"],\n",
    "        [\"music\", \"id\"],\n",
    "        [\"music\", \"original\"],\n",
    "        [\"music\", \"playUrl\"],\n",
    "        [\"music\", \"title\"],\n",
    "    ]\n",
    "\n",
    "    result = {}\n",
    "    for key in keys_to_extract:\n",
    "        if isinstance(key, list):\n",
    "            nested_result = my_dict\n",
    "            for nested_key in key:\n",
    "                if nested_key in nested_result:\n",
    "                    nested_result = nested_result[nested_key]\n",
    "                    # print(nested_key)\n",
    "                else:\n",
    "                    nested_result = None\n",
    "                    break\n",
    "            if nested_result is not None:\n",
    "                result[str(\"_\".join(key))] = nested_result\n",
    "        elif key in my_dict:\n",
    "            result[key] = my_dict[key]\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(contents):\n",
    "    hashtag_arr = []\n",
    "\n",
    "    for content in contents:\n",
    "        for key, textExtra_arr in content.items():\n",
    "            if key == \"textExtra\":\n",
    "                for textExtra in textExtra_arr:\n",
    "                    for key, hashtagName in textExtra.items():\n",
    "                        if key == \"hashtagName\":\n",
    "                            hashtag_arr.append(hashtagName)\n",
    "\n",
    "    # print(hashtag_arr)\n",
    "    joined_string = ', '.join(hashtag_arr)\n",
    "    return joined_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(json_data):\n",
    "    try:\n",
    "        extracted_values = extract_nested_keys(json_data)\n",
    "        # print(json_data)\n",
    "        # print(json_data[\"contents\"])\n",
    "        if json_data[\"contents\"] is None:\n",
    "            return extracted_values\n",
    "        else:\n",
    "            extracted_values[\"hashtagNames\"] = extract_hashtags(json_data[\"contents\"])\n",
    "            # print(str(extracted_values).replace(\"'\",'\"').replace(\"True\", \"true\").replace(\"False\", \"false\"))\n",
    "            # print(type(extracted_values))\n",
    "            return extracted_values\n",
    "    except:\n",
    "        print(\"while extracting some fileds missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(contents):\n",
    "    hashtag_arr = []\n",
    "\n",
    "    for content in contents:\n",
    "        for key, textExtra_arr in content.items():\n",
    "            if key == \"textExtra\":\n",
    "                for textExtra in textExtra_arr:\n",
    "                    for key, hashtagName in textExtra.items():\n",
    "                        if key == \"hashtagName\":\n",
    "                            hashtag_arr.append(hashtagName)\n",
    "\n",
    "    # print(hashtag_arr)\n",
    "    # joined_string = ', '.join(hashtag_arr)\n",
    "    return hashtag_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_csv_file(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0 1997thantzinoo1.txt\n",
      "1997thantzinoo1.txt error inside function\n",
      "while extracting some fileds missing\n",
      "while extracting some fileds missing\n",
      "\n",
      " 1 alocatagram.txt\n",
      "\n",
      " 2 bikesure2.txt\n",
      "bikesure2.txt error inside function\n",
      "\n",
      " 3 diary.f_m.txt\n",
      "\n",
      " 4 evgirl.txt\n",
      "\n",
      " 5 ffern_123.txt\n",
      "while extracting some fileds missing\n",
      "while extracting some fileds missing\n",
      "\n",
      " 6 flipsmile2.txt\n",
      "flipsmile2.txt error inside function\n",
      "\n",
      " 7 geytty.txt\n",
      "while extracting some fileds missing\n",
      "\n",
      " 8 jengtieow.txt\n",
      "jengtieow.txt error inside function\n",
      "\n",
      " 9 kait000n.txt\n",
      "kait000n.txt error inside function\n",
      "while extracting some fileds missing\n",
      "while extracting some fileds missing\n",
      "\n",
      " 10 kim_chiangsong.txt\n",
      "\n",
      " 11 madam.grammy.txt\n",
      "\n",
      " 12 nammon0012.txt\n",
      "while extracting some fileds missing\n",
      "while extracting some fileds missing\n",
      "while extracting some fileds missing\n",
      "while extracting some fileds missing\n",
      "while extracting some fileds missing\n",
      "while extracting some fileds missing\n",
      "\n",
      " 13 nastya.jung.txt\n",
      "\n",
      " 14 pnkkazxz1a.txt\n",
      "\n",
      " 15 rattanaphon_saechio.txt\n",
      "\n",
      " 16 umbrellakuns.txt\n",
      "\n",
      " 17 yfamilyyy.txt\n",
      "yfamilyyy.txt error inside function\n",
      "\n",
      " 18 Yok_jittraphan.txt\n",
      "while extracting some fileds missing\n"
     ]
    }
   ],
   "source": [
    "origin_folder_path = r\"./txt-accounts-files\"\n",
    "csv_file_path = \"AccountPages2.csv\"\n",
    "extracted_df = None\n",
    "\n",
    "clear_csv_file(csv_file_path)\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(origin_folder_path)):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(origin_folder_path, file_name)\n",
    "        print(\"\\n\", i, file_name)\n",
    "\n",
    "        # try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            file_data = file.read()\n",
    "        \n",
    "        json_data_arr = clean_n_decode(file_data, file_name)\n",
    "        extracted_data_json_list = [extract_data(json_data) for json_data in json_data_arr] \n",
    "        \n",
    "        if extracted_df is None:\n",
    "            extracted_df = pd.DataFrame(columns=extracted_data_json_list[0].keys())\n",
    "\n",
    "        filtered_list = [data for data in extracted_data_json_list if data is not None] # one or more elements in your extracted_data_json_list is None instead of a dictionary\n",
    "        df = pd.DataFrame.from_records(filtered_list)\n",
    "        extracted_df = pd.concat([extracted_df, df], ignore_index=True)\n",
    "\n",
    "        # break\n",
    "\n",
    "        \n",
    "        # for json_data in extracted_data_json_list:\n",
    "        #     df = pd.DataFrame(json_data)\n",
    "        #     extracted_df = pd.concat([extracted_df, df], ignore_index=True)\n",
    "            \n",
    "        # except:\n",
    "        #     print(file_name + ' error')\n",
    "\n",
    "extracted_df.to_csv(csv_file_path, mode='a', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data_json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'header'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DeRoxy\\Documents\\GitHub\\CloudNC\\Botnoi-Data-Science-Essential-8\\data analytic team project\\AccountPage\\AccountPage-loop.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/DeRoxy/Documents/GitHub/CloudNC/Botnoi-Data-Science-Essential-8/data%20analytic%20team%20project/AccountPage/AccountPage-loop.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m extracted_df\u001b[39m.\u001b[39;49mheader()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'header'"
     ]
    }
   ],
   "source": [
    "extracted_df.header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_uniqueId</th>\n",
       "      <th>author_signature</th>\n",
       "      <th>author_verified</th>\n",
       "      <th>desc</th>\n",
       "      <th>createTime</th>\n",
       "      <th>digged</th>\n",
       "      <th>duetDisplay</th>\n",
       "      <th>duetEnabled</th>\n",
       "      <th>forFriend</th>\n",
       "      <th>id</th>\n",
       "      <th>itemCommentStatus</th>\n",
       "      <th>music_authorName</th>\n",
       "      <th>music_coverLarge</th>\n",
       "      <th>music_duration</th>\n",
       "      <th>music_id</th>\n",
       "      <th>music_original</th>\n",
       "      <th>music_playUrl</th>\n",
       "      <th>music_title</th>\n",
       "      <th>hashtagNames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997thantzinoo1</td>\n",
       "      <td>FB = Thant Zin Oo page = 1997kothantzin Line =...</td>\n",
       "      <td>False</td>\n",
       "      <td>@Win Thu Aung</td>\n",
       "      <td>1697677280</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>7291468383554407685</td>\n",
       "      <td>0</td>\n",
       "      <td>ðŸ–¤MyoThiHaKyawðŸ–¤</td>\n",
       "      <td>https://p16-sign-sg.tiktokcdn.com/aweme/1080x1...</td>\n",
       "      <td>23</td>\n",
       "      <td>7260431444898581250</td>\n",
       "      <td>False</td>\n",
       "      <td>https://v16-webapp-prime.tiktok.com/video/tos/...</td>\n",
       "      <td>original sound - ðŸ–¤MyoThiHaKyawðŸ–¤</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_uniqueId                                   author_signature  \\\n",
       "0  1997thantzinoo1  FB = Thant Zin Oo page = 1997kothantzin Line =...   \n",
       "\n",
       "   author_verified            desc  createTime  digged  duetDisplay  \\\n",
       "0            False  @Win Thu Aung   1697677280   False            0   \n",
       "\n",
       "   duetEnabled  forFriend                   id  itemCommentStatus  \\\n",
       "0         True      False  7291468383554407685                  0   \n",
       "\n",
       "  music_authorName                                   music_coverLarge  \\\n",
       "0   ðŸ–¤MyoThiHaKyawðŸ–¤  https://p16-sign-sg.tiktokcdn.com/aweme/1080x1...   \n",
       "\n",
       "   music_duration             music_id  music_original  \\\n",
       "0              23  7260431444898581250           False   \n",
       "\n",
       "                                       music_playUrl  \\\n",
       "0  https://v16-webapp-prime.tiktok.com/video/tos/...   \n",
       "\n",
       "                       music_title hashtagNames  \n",
       "0  original sound - ðŸ–¤MyoThiHaKyawðŸ–¤               "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1997thantzinoo1.txt error inside function\n",
      "1997thantzinoo1.txt error\n",
      "bikesure2.txt error inside function\n",
      "ffern_123.txt error\n",
      "flipsmile2.txt error inside function\n",
      "geytty.txt error\n",
      "jengtieow.txt error inside function\n",
      "kait000n.txt error inside function\n",
      "kait000n.txt error\n",
      "nammon0012.txt error\n",
      "yfamilyyy.txt error inside function\n",
      "Yok_jittraphan.txt error\n"
     ]
    }
   ],
   "source": [
    "origin_folder_path = r\"./txt-accounts-files\"\n",
    "csv_file_path = \"AccountPages.csv\"\n",
    "extracted_df = None\n",
    "\n",
    "clear_csv_file(csv_file_path)\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(origin_folder_path)):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(origin_folder_path, file_name)\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"r\") as file:\n",
    "                file_data = file.read()\n",
    "\n",
    "            json_data_arr = clean_n_decode(file_data, file_name)\n",
    "            extracted_data_json_list = [extract_data(json_data) for json_data in json_data_arr]\n",
    "\n",
    "            if i == 0:\n",
    "                extracted_df = pd.DataFrame(columns=extracted_data_json_list[0].keys())\n",
    "\n",
    "            df = pd.DataFrame(extracted_data_json_list)\n",
    "            dataframes.append(df)\n",
    "\n",
    "        except:\n",
    "            print(file_name + ' error')\n",
    "\n",
    "extracted_df = pd.concat(dataframes, ignore_index=True)\n",
    "extracted_df.to_csv(csv_file_path, mode='a', header=True, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
